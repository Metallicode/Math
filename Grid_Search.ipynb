{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1Vfp9d-Rv2nM"
      ],
      "authorship_tag": "ABX9TyNMKz7zhxBjD6a+ZlcYLDvp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Metallicode/Math/blob/main/Grid_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k235q8JhfILX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Advertising.csv\")"
      ],
      "metadata": {
        "id": "_Kcvh4f7pQZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"sales\"]\n",
        "\n",
        "X = df.drop([\"sales\"], axis=1)"
      ],
      "metadata": {
        "id": "tw2LYVxMpXUT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=True)"
      ],
      "metadata": {
        "id": "eWopitFnpgOF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "iaGgGfVVphTe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid Search"
      ],
      "metadata": {
        "id": "zCazKBBxrLPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create a model that used multiple Hyper-Parameters"
      ],
      "metadata": {
        "id": "arvcI6Q9sTM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet"
      ],
      "metadata": {
        "id": "7YVXdBHdsPWR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(ElasticNet)  ##examin the model parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOVMKMpJsohH",
        "outputId": "0a6e9d3f-5dde-49da-daa8-56a3a6b27999"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class ElasticNet in module sklearn.linear_model._coordinate_descent:\n",
            "\n",
            "class ElasticNet(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
            " |  ElasticNet(alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
            " |  \n",
            " |  Linear regression with combined L1 and L2 priors as regularizer.\n",
            " |  \n",
            " |  Minimizes the objective function::\n",
            " |  \n",
            " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
            " |          + alpha * l1_ratio * ||w||_1\n",
            " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
            " |  \n",
            " |  If you are interested in controlling the L1 and L2 penalty\n",
            " |  separately, keep in mind that this is equivalent to::\n",
            " |  \n",
            " |          a * ||w||_1 + 0.5 * b * ||w||_2^2\n",
            " |  \n",
            " |  where::\n",
            " |  \n",
            " |          alpha = a + b and l1_ratio = a / (a + b)\n",
            " |  \n",
            " |  The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
            " |  alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
            " |  = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
            " |  unless you supply your own sequence of alpha.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <elastic_net>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  alpha : float, default=1.0\n",
            " |      Constant that multiplies the penalty terms. Defaults to 1.0.\n",
            " |      See the notes for the exact mathematical meaning of this\n",
            " |      parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
            " |      solved by the :class:`LinearRegression` object. For numerical\n",
            " |      reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
            " |      Given this, you should use the :class:`LinearRegression` object.\n",
            " |  \n",
            " |  l1_ratio : float, default=0.5\n",
            " |      The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
            " |      ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
            " |      is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
            " |      combination of L1 and L2.\n",
            " |  \n",
            " |  fit_intercept : bool, default=True\n",
            " |      Whether the intercept should be estimated or not. If ``False``, the\n",
            " |      data is assumed to be already centered.\n",
            " |  \n",
            " |  precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
            " |      Whether to use a precomputed Gram matrix to speed up\n",
            " |      calculations. The Gram matrix can also be passed as argument.\n",
            " |      For sparse input this option is always ``False`` to preserve sparsity.\n",
            " |  \n",
            " |  max_iter : int, default=1000\n",
            " |      The maximum number of iterations.\n",
            " |  \n",
            " |  copy_X : bool, default=True\n",
            " |      If ``True``, X will be copied; else, it may be overwritten.\n",
            " |  \n",
            " |  tol : float, default=1e-4\n",
            " |      The tolerance for the optimization: if the updates are\n",
            " |      smaller than ``tol``, the optimization code checks the\n",
            " |      dual gap for optimality and continues until it is smaller\n",
            " |      than ``tol``, see Notes below.\n",
            " |  \n",
            " |  warm_start : bool, default=False\n",
            " |      When set to ``True``, reuse the solution of the previous call to fit as\n",
            " |      initialization, otherwise, just erase the previous solution.\n",
            " |      See :term:`the Glossary <warm_start>`.\n",
            " |  \n",
            " |  positive : bool, default=False\n",
            " |      When set to ``True``, forces the coefficients to be positive.\n",
            " |  \n",
            " |  random_state : int, RandomState instance, default=None\n",
            " |      The seed of the pseudo random number generator that selects a random\n",
            " |      feature to update. Used when ``selection`` == 'random'.\n",
            " |      Pass an int for reproducible output across multiple function calls.\n",
            " |      See :term:`Glossary <random_state>`.\n",
            " |  \n",
            " |  selection : {'cyclic', 'random'}, default='cyclic'\n",
            " |      If set to 'random', a random coefficient is updated every iteration\n",
            " |      rather than looping over features sequentially by default. This\n",
            " |      (setting to 'random') often leads to significantly faster convergence\n",
            " |      especially when tol is higher than 1e-4.\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
            " |      Parameter vector (w in the cost function formula).\n",
            " |  \n",
            " |  sparse_coef_ : sparse matrix of shape (n_features,) or             (n_targets, n_features)\n",
            " |      Sparse representation of the `coef_`.\n",
            " |  \n",
            " |  intercept_ : float or ndarray of shape (n_targets,)\n",
            " |      Independent term in decision function.\n",
            " |  \n",
            " |  n_iter_ : list of int\n",
            " |      Number of iterations run by the coordinate descent solver to reach\n",
            " |      the specified tolerance.\n",
            " |  \n",
            " |  dual_gap_ : float or ndarray of shape (n_targets,)\n",
            " |      Given param alpha, the dual gaps at the end of the optimization,\n",
            " |      same shape as each observation of y.\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  ElasticNetCV : Elastic net model with best model selection by\n",
            " |      cross-validation.\n",
            " |  SGDRegressor : Implements elastic net regression with incremental training.\n",
            " |  SGDClassifier : Implements logistic regression with elastic net penalty\n",
            " |      (``SGDClassifier(loss=\"log_loss\", penalty=\"elasticnet\")``).\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  To avoid unnecessary memory duplication the X argument of the fit method\n",
            " |  should be directly passed as a Fortran-contiguous numpy array.\n",
            " |  \n",
            " |  The precise stopping criteria based on `tol` are the following: First, check that\n",
            " |  that maximum coordinate update, i.e. :math:`\\max_j |w_j^{new} - w_j^{old}|`\n",
            " |  is smaller than `tol` times the maximum absolute coefficient, :math:`\\max_j |w_j|`.\n",
            " |  If so, then additionally check whether the dual gap is smaller than `tol` times\n",
            " |  :math:`||y||_2^2 / n_{      ext{samples}}`.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.linear_model import ElasticNet\n",
            " |  >>> from sklearn.datasets import make_regression\n",
            " |  \n",
            " |  >>> X, y = make_regression(n_features=2, random_state=0)\n",
            " |  >>> regr = ElasticNet(random_state=0)\n",
            " |  >>> regr.fit(X, y)\n",
            " |  ElasticNet(random_state=0)\n",
            " |  >>> print(regr.coef_)\n",
            " |  [18.83816048 64.55968825]\n",
            " |  >>> print(regr.intercept_)\n",
            " |  1.451...\n",
            " |  >>> print(regr.predict([[0, 0]]))\n",
            " |  [1.451...]\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      ElasticNet\n",
            " |      sklearn.base.MultiOutputMixin\n",
            " |      sklearn.base.RegressorMixin\n",
            " |      sklearn.linear_model._base.LinearModel\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None, check_input=True)\n",
            " |      Fit model with coordinate descent.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {ndarray, sparse matrix} of (n_samples, n_features)\n",
            " |          Data.\n",
            " |      \n",
            " |      y : {ndarray, sparse matrix} of shape (n_samples,) or             (n_samples, n_targets)\n",
            " |          Target. Will be cast to X's dtype if necessary.\n",
            " |      \n",
            " |      sample_weight : float or array-like of shape (n_samples,), default=None\n",
            " |          Sample weights. Internally, the `sample_weight` vector will be\n",
            " |          rescaled to sum to `n_samples`.\n",
            " |      \n",
            " |          .. versionadded:: 0.23\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you do.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Fitted estimator.\n",
            " |      \n",
            " |      Notes\n",
            " |      -----\n",
            " |      Coordinate descent is an algorithm that considers each column of\n",
            " |      data at a time hence it will automatically convert the X input\n",
            " |      as a Fortran-contiguous numpy array if necessary.\n",
            " |      \n",
            " |      To avoid memory re-allocation it is advised to allocate the\n",
            " |      initial data in memory directly using that format.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
            " |      Compute elastic net path with coordinate descent.\n",
            " |      \n",
            " |      The elastic net optimization function varies for mono and multi-outputs.\n",
            " |      \n",
            " |      For mono-output tasks it is::\n",
            " |      \n",
            " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
            " |          + alpha * l1_ratio * ||w||_1\n",
            " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
            " |      \n",
            " |      For multi-output tasks it is::\n",
            " |      \n",
            " |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
            " |          + alpha * l1_ratio * ||W||_21\n",
            " |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
            " |      \n",
            " |      Where::\n",
            " |      \n",
            " |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
            " |      \n",
            " |      i.e. the sum of norm of each row.\n",
            " |      \n",
            " |      Read more in the :ref:`User Guide <elastic_net>`.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
            " |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
            " |          can be sparse.\n",
            " |      \n",
            " |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
            " |          Target values.\n",
            " |      \n",
            " |      l1_ratio : float, default=0.5\n",
            " |          Number between 0 and 1 passed to elastic net (scaling between\n",
            " |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
            " |      \n",
            " |      eps : float, default=1e-3\n",
            " |          Length of the path. ``eps=1e-3`` means that\n",
            " |          ``alpha_min / alpha_max = 1e-3``.\n",
            " |      \n",
            " |      n_alphas : int, default=100\n",
            " |          Number of alphas along the regularization path.\n",
            " |      \n",
            " |      alphas : ndarray, default=None\n",
            " |          List of alphas where to compute the models.\n",
            " |          If None alphas are set automatically.\n",
            " |      \n",
            " |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
            " |          Whether to use a precomputed Gram matrix to speed up\n",
            " |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
            " |          matrix can also be passed as argument.\n",
            " |      \n",
            " |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
            " |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
            " |          only when the Gram matrix is precomputed.\n",
            " |      \n",
            " |      copy_X : bool, default=True\n",
            " |          If ``True``, X will be copied; else, it may be overwritten.\n",
            " |      \n",
            " |      coef_init : ndarray of shape (n_features, ), default=None\n",
            " |          The initial values of the coefficients.\n",
            " |      \n",
            " |      verbose : bool or int, default=False\n",
            " |          Amount of verbosity.\n",
            " |      \n",
            " |      return_n_iter : bool, default=False\n",
            " |          Whether to return the number of iterations or not.\n",
            " |      \n",
            " |      positive : bool, default=False\n",
            " |          If set to True, forces coefficients to be positive.\n",
            " |          (Only allowed when ``y.ndim == 1``).\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          If set to False, the input validation checks are skipped (including the\n",
            " |          Gram matrix when provided). It is assumed that they are handled\n",
            " |          by the caller.\n",
            " |      \n",
            " |      **params : kwargs\n",
            " |          Keyword arguments passed to the coordinate descent solver.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      alphas : ndarray of shape (n_alphas,)\n",
            " |          The alphas along the path where models are computed.\n",
            " |      \n",
            " |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
            " |          Coefficients along the path.\n",
            " |      \n",
            " |      dual_gaps : ndarray of shape (n_alphas,)\n",
            " |          The dual gaps at the end of the optimization for each alpha.\n",
            " |      \n",
            " |      n_iters : list of int\n",
            " |          The number of iterations taken by the coordinate descent optimizer to\n",
            " |          reach the specified tolerance for each alpha.\n",
            " |          (Is returned when ``return_n_iter`` is set to True).\n",
            " |      \n",
            " |      See Also\n",
            " |      --------\n",
            " |      MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
            " |      MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
            " |      ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
            " |      ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
            " |      \n",
            " |      Notes\n",
            " |      -----\n",
            " |      For an example, see\n",
            " |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
            " |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  sparse_coef_\n",
            " |      Sparse representation of the fitted `coef_`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.RegressorMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the coefficient of determination of the prediction.\n",
            " |      \n",
            " |      The coefficient of determination :math:`R^2` is defined as\n",
            " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
            " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
            " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
            " |      The best possible score is 1.0 and it can be negative (because the\n",
            " |      model can be arbitrarily worse). A constant model that always predicts\n",
            " |      the expected value of `y`, disregarding the input features, would get\n",
            " |      a :math:`R^2` score of 0.0.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples. For some estimators this may be a precomputed\n",
            " |          kernel matrix or a list of generic objects instead with shape\n",
            " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
            " |          is the number of samples used in the fitting for the estimator.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True values for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
            " |      \n",
            " |      Notes\n",
            " |      -----\n",
            " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
            " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
            " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
            " |      This influences the ``score`` method of all the multioutput\n",
            " |      regressors (except for\n",
            " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict using the linear model.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
            " |          Samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      C : array, shape (n_samples,)\n",
            " |          Returns predicted values.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create the Model"
      ],
      "metadata": {
        "id": "o9nF3AUitJ7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ElasticNet()"
      ],
      "metadata": {
        "id": "a3AwZRPEs3G7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Hyper-Params values Dict"
      ],
      "metadata": {
        "id": "9AOdMfN9tM6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_dict = {\"alpha\":[100,10,1,0.1,0.01],\n",
        "               \"l1_ratio\":[0.1,0.3,0.5,0.8,0.9,0.99,1]}"
      ],
      "metadata": {
        "id": "b3KGVjs8tVXI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###import GridSearchCV"
      ],
      "metadata": {
        "id": "tJxp7ZB-t_5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "PAjtW23ouLTS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_model = GridSearchCV(estimator=base_model,\n",
        "                          param_grid=params_dict,\n",
        "                          scoring=\"neg_mean_squared_error\",\n",
        "                          cv=5,verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "##For a list of score strings\n",
        "##https://scikit-learn.org/stable/modules/model_evaluation.html"
      ],
      "metadata": {
        "id": "VL3tSPtAuehf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fit the GridSearchCV model"
      ],
      "metadata": {
        "id": "1Vfp9d-Rv2nM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "6EVFAE7svjsi",
        "outputId": "d17382fc-fd89-457f-c522-9c5466a4ed5e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
              "             param_grid={'alpha': [100, 10, 1, 0.1, 0.01],\n",
              "                         'l1_ratio': [0.1, 0.3, 0.5, 0.8, 0.9, 0.99, 1]},\n",
              "             scoring='neg_mean_squared_error', verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
              "             param_grid={&#x27;alpha&#x27;: [100, 10, 1, 0.1, 0.01],\n",
              "                         &#x27;l1_ratio&#x27;: [0.1, 0.3, 0.5, 0.8, 0.9, 0.99, 1]},\n",
              "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
              "             param_grid={&#x27;alpha&#x27;: [100, 10, 1, 0.1, 0.01],\n",
              "                         &#x27;l1_ratio&#x27;: [0.1, 0.3, 0.5, 0.8, 0.9, 0.99, 1]},\n",
              "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_model.best_estimator_\n",
        "\n",
        "#grid_model.best_params_     #pretty much the same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "2VXPjqQ6v-cm",
        "outputId": "9c0950ce-5f34-43d9-c3cb-eb67e707da6d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=0.1, l1_ratio=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.1, l1_ratio=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.1, l1_ratio=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Full CV Report"
      ],
      "metadata": {
        "id": "UIcfp448wgw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_model.cv_results_"
      ],
      "metadata": {
        "id": "blNSN_SowASa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_hyper_params_report = pd.DataFrame(grid_model.cv_results_)"
      ],
      "metadata": {
        "id": "4xlo9Zh5wmOL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_hyper_params_report"
      ],
      "metadata": {
        "id": "DHcD4Pnsw2-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Predict"
      ],
      "metadata": {
        "id": "HMxXe-zvxHVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = grid_model.predict(X_test)"
      ],
      "metadata": {
        "id": "NzQkmSwXxJNN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluate"
      ],
      "metadata": {
        "id": "tGIPTcg-xQBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "zuLXXZ-dxN26"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkO4m4MpxZxf",
        "outputId": "3f3f024f-4182-41de-afdc-357baa5af42e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.964614242512318"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}